{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('api.config')\n",
    "\n",
    "openai_key = config['OpenAI']['API_KEY']\n",
    "serperdev_key = config['SerperDev']['SerpDEV_API_KEY']\n",
    "serperapi_key = config['SerpAPI']['SerpAPI_API_KEY']\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = openai_key\n",
    "os.environ['SERPER_API_KEY'] = serperdev_key\n",
    "os.environ['SERPAPI_API_KEY'] = serperapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAI(temperature=0.2)\n",
    "txt_template = \"\"\"You are a Problem Solver. Given the problem sentence and its category, it is your job to \n",
    "write a the pseudo code for that problem and print out.\n",
    "\n",
    "Problem Sentence: {prob_statement}\n",
    "Problem Solver: This is a psuedo code for the above problem statement:\"\"\"\n",
    "\n",
    "my_prompt = PromptTemplate(input_variables=['prob_statement'],\n",
    "                           template=txt_template)\n",
    "\n",
    "chain = LLMChain(llm=model,prompt=my_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.run(\"Design a program that calculates the area of a circle when the radius is given as input.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "// Declare a function to calculate the area of a circle\n",
      "FUNCTION calculateAreaOfCircle(radius)\n",
      "    // Calculate the area of the circle\n",
      "    area = PI * radius * radius\n",
      "    \n",
      "    // Return the area\n",
      "    RETURN area\n",
      "END FUNCTION\n",
      "\n",
      "// Declare a variable to store the radius\n",
      "DECLARE radius\n",
      "\n",
      "// Ask the user to enter the radius\n",
      "PRINT \"Please enter the radius of the circle: \"\n",
      "INPUT radius\n",
      "\n",
      "// Call the function to calculate the area\n",
      "area = calculateAreaOfCircle(radius)\n",
      "\n",
      "// Print the area\n",
      "PRINT \"The area of the circle is: \" + area\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAI(temperature=0.4)\n",
    "#model2 = OpenAI(temperature=0.2)\n",
    "text_1 = \"\"\"You are a Computer salesmen expert who specialize in Laptop sales. It is your job to provide a list of top 5 laptops base on given criteria. List should contain name and price.\n",
    "Criteria: {criteria}\n",
    "This is a recommended laptop list:\n",
    "\"\"\"\n",
    "prompt_1 = PromptTemplate(input_variables=['criteria'],\n",
    "                          template=text_1)\n",
    "product_chain = LLMChain(llm=model,prompt=prompt_1)\n",
    "\n",
    "text_2 = \"\"\"You are a price expert who can rank products provided in the Product List from cheapert to most expensive.\n",
    "Product List: {product_list}\n",
    "List of procucts ranked from cheapest:  \n",
    "\"\"\"\n",
    "prompt_2 = PromptTemplate(input_variables=['product_list'],template=text_2)\n",
    "list_chain = LLMChain(llm=model,prompt=prompt_2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[product_chain,list_chain], verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Lenovo ThinkPad X1 Carbon (14”) – $1,859.00\n",
      "2. Dell XPS 13 (13.3”) – $1,099.99\n",
      "3. HP Spectre x360 (13.3”) – $1,599.99\n",
      "4. ASUS ROG Zephyrus G14 (14”) – $1,449.99\n",
      "5. Apple MacBook Pro (13”) – $1,299.00\n"
     ]
    }
   ],
   "source": [
    "print(overall.run(\"price and performance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "1. Lenovo ThinkPad X1 Carbon (14-inch) - $1,499\n",
      "2. Asus ROG Zephyrus G14 - $1,049\n",
      "3. Dell XPS 15 (2020) - $1,799\n",
      "4. HP Spectre x360 (2020) - $1,499\n",
      "5. Apple MacBook Pro (16-inch, 2019) - $2,399\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m1. Asus ROG Zephyrus G14 - $1,049\n",
      "2. Lenovo ThinkPad X1 Carbon (14-inch) - $1,499\n",
      "3. HP Spectre x360 (2020) - $1,499\n",
      "4. Dell XPS 15 (2020) - $1,799\n",
      "5. Apple MacBook Pro (16-inch, 2019) - $2,399\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "1. Asus ROG Zephyrus G14 - $1,049\n",
      "2. Lenovo ThinkPad X1 Carbon (14-inch) - $1,499\n",
      "3. HP Spectre x360 (2020) - $1,499\n",
      "4. Dell XPS 15 (2020) - $1,799\n",
      "5. Apple MacBook Pro (16-inch, 2019) - $2,399\n"
     ]
    }
   ],
   "source": [
    "print(overall_chain.run(\"price and performance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "happy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
